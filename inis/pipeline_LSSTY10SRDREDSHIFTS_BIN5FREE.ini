; Env variables to define in your job script (different for each user)
; CSL_DIR - path to your cosmosis-standard-libarary
; Y6METHODDIR - path to y6-3x2pt-methods/y6_fiducial
; OUTPUT_DIR - directory where you want chain output to go

; env variables that should be defined in the shared job sh file:
; DATA_TAG, MODEL_TAG, LENS_TAG, OUTPUT_TAG, SAMPLER, DATA_VECTOR, SCALE_CUTS
; DATA_VECTOR_SR, EXTRA_OUTPUT


[runtime]

; note that inclusion of sampler ini file at end of this script will override this
sampler = test
root = ${CSL_DIR}

; ### SETTINGS ###
[DEFAULT]
2PT_FILE = data_vectors/${DATA_VECTOR}
SR_FILE = data_vectors/${DATA_VECTOR_SR}

SR_MODULE =
; Used for euclid emulator, nonlinear bias_marg (default is to leve blank)
ACTION_POSTPK =
; used for including other likelihoods ( e.g. shear ratio, extenral data) or save_2pt
ACTION_POSTLIKE = ${SAVE}

;data and likelihoods
2PT_DATA_SETS = xip xim 

; used to find values file
INI_RUN_NAME = ${DATA_TAG}_${MODEL_TAG}
; used for output filenames:
LONG_RUN_NAME=${DATA_TAG}_${MODEL_TAG}.${SAMPLER}.${DATA_VECTOR}.${SCALE_CUTS}

[output]
filename= $OUTPUT_DIR/chain_%(LONG_RUN_NAME)s.txt
format=text
lock=F
privacy=F

; ### PIPELINE ###
[pipeline]
modules =  consistency  bbn_consistency camb  extrapolate %(ACTION_POSTPK)s fast_pt
           fits_nz  source_photoz_bias IA   pk_to_cl add_intrinsic
           2pt_shear shear_m_bias 2pt_like  %(ACTION_POSTLIKE)s

quiet=T
timing=F
debug=F

priors = $Y6METHODSDIR/inis/priors_SRDREDSHIFTLSSTY10_BIN5FREE.ini
values = $Y6METHODSDIR/inis/values_shear_fixnu_nla.ini
extra_output = cosmological_parameters/S_8 cosmological_parameters/sigma_8 cosmological_parameters/sigma_12 data_vector/2pt_chi2 ${EXTRA_OUTPUT}
fast_slow = F
first_fast_module = shear_m_bias
; For some use cases this might be faster:
;first_fast_module=lens_photoz_width



; ### SAMPLERS ###
; many settings will get overridden by ini files in
; sampler_def_ini file direcotry, but need to define base modules here

[test]
save_dir=test_samplers/test_%(LONG_RUN_NAME)s

[polychord]
base_dir=$OUTPUT_DIR
polychord_outfile_root=pc_%(LONG_RUN_NAME)s
resume = T
feedback = 3
fast_fraction = 0.1
live_points = 500
num_repeats = 60
tolerance = 0.01
boost_posteriors=10.0

[multinest]
max_iterations=50000
multinest_outfile_root=multinest_files/mn_%(LONG_RUN_NAME)s
resume=T
live_points=500
efficiency=0.3
tolerance=0.01
constant_efficiency=F

; ### MODULES ###
[consistency]
file = utility/consistency/consistency_interface.py
verbose=T

[camb]
file = boltzmann/camb/camb_interface.py
mode = power
lmax = 2500          ;max ell to use for cmb calculation
feedback=3         ;amount of output to print
AccuracyBoost=1.1 ;CAMB accuracy boost parameter
do_tensors = T
do_lensing = T
NonLinear = pk
halofit_version = mead2020
zmin_background = 0.
zmax_background = 4.
nz_background = 401
kmin=1e-4
kmax = 50.0
kmax_extrapolate = 500.0
nk=700
nz=100

[sigma8_rescale]
file = utility/sample_sigma8/sigma8_rescale.py

[euclid_emulator]
file = structure/EuclidEmulator2/euclid_emulator2_interface.py

[bias_marg]
file = bias/bias_marg/bias_marg.py

[bbn_consistency]
file = utility/bbn_consistency/bbn_consistency.py

[extrapolate]
file = boltzmann/extrapolate/extrapolate_power.py
kmax = 500.

[fits_nz]
file = number_density/load_nz_fits/load_nz_fits.py
nz_file = %(2PT_FILE)s
data_sets = source
prefix_section = T
prefix_extension = T

[fits_nz_lens]
file = number_density/load_nz_fits/load_nz_fits.py
nz_file = %(2PT_FILE)s
data_sets = lens
prefix_section = T
prefix_extension = T

[lens_photoz_width]
file = number_density/photoz_width/photoz_width.py
mode = stretch
sample = nz_lens
bias_section = lens_photoz_errors
interpolation = linear

[lens_photoz_bias]
file = number_density/photoz_bias/photoz_bias.py
mode = additive
sample = nz_lens
bias_section = lens_photoz_errors
interpolation = linear

; hyperrank and source_photoz_bias are exclusive
[hyperrank]
file = number_density/nz_multirank/nz_multirank.py
nz_file = %(2PT_FILE)s
data_set = source
dimensions = 3
bin_ranks= 1 2 4

[source_photoz_bias]
file = number_density/photoz_bias/photoz_bias.py
mode = additive
sample = nz_source
bias_section = wl_photoz_errors
interpolation = linear

[fast_pt]
file = structure/fast_pt/fast_pt_interface.py
do_ia = T
k_res_fac = 0.5
verbose = F

[IA]
file = intrinsic_alignments/tatt/tatt_interface.py
sub_lowk = F
do_galaxy_intrinsic = F
ia_model = tatt

[pk_to_cl_gg]
file = structure/projection/project_2d.py
lingal-lingal = lens-lens
do_exact = lingal-lingal
do_rsd = True
ell_min_linspaced = 1
ell_max_linspaced = 4
n_ell_linspaced = 5
ell_min_logspaced = 5.
ell_max_logspaced = 5.e5
n_ell_logspaced = 80
limber_ell_start = 200
ell_max_logspaced=1.e5
auto_only=lingal-lingal
sig_over_dchi_exact = 3.5

[pk_to_cl]
file = structure/projection/project_2d.py
ell_min_logspaced = 0.1
ell_max_logspaced = 5.0e5
n_ell_logspaced = 100
shear-shear = source-source
shear-intrinsic = source-source
intrinsic-intrinsic = source-source
intrinsicb-intrinsicb=source-source
lingal-magnification = 
magnification-magnification =
lingal-shear =
lingal-intrinsic =
magnification-shear =
magnification-intrinsic =
;lingal-shear = lens-source
;lingal-intrinsic = lens-source
;lingal-magnification = lens-lens
;magnification-shear = lens-source
;magnification-magnification = lens-lens
;magnification-intrinsic = lens-source
verbose = F
;get_kernel_peaks = F
;sig_over_dchi = 20.
;shear_kernel_dchi = 10.
;auto_only=

[add_magnification]
file = structure/magnification/add_magnification.py
include_intrinsic=T

[add_intrinsic]
file=shear/add_intrinsic/add_intrinsic.py
shear-shear=T
position-shear=F
perbin=F

;[add_eb]
;file = intrinsic_alignments/add_b_mode/add_b_mode_cl.py

[2pt_shear]
file = shear/cl_to_xi_fullsky/cl_to_xi_interface.py
ell_max = 40000
xi_type = EB
theta_file=%(2PT_FILE)s
bin_avg = T
; these get
input_section_name = shear_cl  shear_cl_bb
output_section_name = shear_xi_plus  shear_xi_minus

[2pt_gal]
file = shear/cl_to_xi_fullsky/cl_to_xi_interface.py
ell_max = 40000
xi_type='00'
theta_file=%(2PT_FILE)s
bin_avg = T

[2pt_gal_shear]
file = shear/cl_to_xi_fullsky/cl_to_xi_interface.py
ell_max = 40000
xi_type='02'
theta_file=%(2PT_FILE)s
bin_avg = T

[shear_m_bias]
file = shear/shear_bias/shear_m_bias.py
m_per_bin = True
; Despite the parameter name, this can operate on xi as well as C_ell.
cl_section = shear_xi_plus shear_xi_minus
cross_section = galaxy_shear_xi
verbose = F

[add_point_mass]
file=shear/point_mass/add_gammat_point_mass.py
add_togammat = False
use_fiducial = True
sigcrit_inv_section = sigma_crit_inv_lens_source

[2pt_like]
file = likelihood/2pt/2pt_point_mass/2pt_point_mass.py



do_pm_marg = True
do_pm_sigcritinv = True
sigma_a = 10000.0
no_det_fac = False
include_norm = True
data_file = %(2PT_FILE)s
data_sets =  %(2PT_DATA_SETS)s
make_covariance=F
covmat_name=COVMAT

; we put these in a separate file because they are long
%include scale_cuts/${SCALE_CUTS}



; The small-scale galaxy galaxy-lensing correlations have uncertain
; enough modelling that we can't use them directly, but the ratio between
; sets of correlations can be used, since it only depends on geometry
; NOTE THAT THE SETTINGS HERE DEPEND ON THE LENS SAMPLE, note lenstag in name
[shear_ratio_like_ml4]
file = likelihood/des-y3/shear_ratio/shear_ratio_likelihood.py
data_file = %(SR_FILE)s
theta_min_1 = 9.0  6.0  4.5  2.5  2.5
theta_min_2 = 9.0  6.0  4.5  2.5  2.5
theta_min_3 = 2.5  2.5  4.5  2.5  2.5
theta_max = 26.83313651 17.63634989 13.61215672 11.32891161 10.01217238
include_norm = T


; ### EXTERNAL LIKELIHOODS ###

;;CMB;;
[p-TTTEEE-lowE]
;Planck 2018 high ell TT,TE and EE + low ell TT + low ell EE (in Planck notations = TT+lowE)
;without CMB lensing
file = likelihood/planck2018/planck_interface.so
;high ell TT,TE and EE
data_1 = ${PLANCKPATH}/hi_l/plik/plik_rd12_HM_v22b_TTTEEE.clik
;low ell TT
data_2 = ${PLANCKPATH}/low_l/commander/commander_dx12_v3_2_29.clik
;low ell EE
data_3 = ${PLANCKPATH}/low_l/simall/simall_100x143_offlike5_EE_Aplanck_B.clik

[p-TTTEEE_lite-lowE]
;Planck 2018 high ell TT,TE and EE + low ell TT + low ell EE (in Planck notations = TT+lowE)
;without CMB lensing
file = likelihood/planck2018/planck_interface.so
;high ell TT,TE and EE lite
data_1 = ${PLANCKPATH}/hi_l/plik_lite/plik_lite_v22_TTTEEE.clik
;low ell TT
data_2 = ${PLANCKPATH}/low_l/commander/commander_dx12_v3_2_29.clik
;low ell EE
data_3 = ${PLANCKPATH}/low_l/simall/simall_100x143_offlike5_EE_Aplanck_B.clik

[p-TTTEEE-lowE-lensing]
;Planck 2018 high ell TT,TE and EE + low ell TT + low ell EE (in Planck notations = TT+lowE)
;with CMB lensing
file = likelihood/planck2018/planck_interface.so
;high ell TT,TE and EE
data_1 = ${PLANCKPATH}/hi_l/plik/plik_rd12_HM_v22b_TTTEEE.clik
;low ell TT
data_2 = ${PLANCKPATH}/low_l/commander/commander_dx12_v3_2_29.clik
;low ell EE
data_3 = ${PLANCKPATH}/low_l/simall/simall_100x143_offlike5_EE_Aplanck_B.clik
;lensing
lensing_1 = ${PLANCKPATH}/lensing/smicadx12_Dec5_ftl_mv2_ndclpp_p_teb_consext8.clik_lensing

[p-TTTEEE_lite-lensing]
;Planck 2018 high ell TT,TE and EE + low ell TT + low ell EE (in Planck notations = TT+lowE)
;without CMB lensing
file = likelihood/planck2018/planck_interface.so
;high ell TT,TE and EE lite
data_1 = ${PLANCKPATH}/hi_l/plik_lite/plik_lite_v22_TTTEEE.clik
;lensing
lensing_1 = ${PLANCKPATH}/lensing/smicadx12_Dec5_ftl_mv2_ndclpp_p_teb_consext8.clik_lensing

[p-TTTEEE_lite-lowE-lensing]
;Planck 2018 high ell TT,TE and EE + low ell TT + low ell EE (in Planck notations = TT+lowE)
;without CMB lensing
file = likelihood/planck2018/planck_interface.so
;high ell TT,TE and EE lite
data_1 = ${PLANCKPATH}/hi_l/plik_lite/plik_lite_v22_TTTEEE.clik
;low ell TT
data_2 = ${PLANCKPATH}/low_l/commander/commander_dx12_v3_2_29.clik
;low ell EE
data_3 = ${PLANCKPATH}/low_l/simall/simall_100x143_offlike5_EE_Aplanck_B.clik
;lensing
lensing_1 = ${PLANCKPATH}/lensing/smicadx12_Dec5_ftl_mv2_ndclpp_p_teb_consext8.clik_lensing

[p-lensing]
;Planck 2018 CMB lensing
file = likelihood/planck2018/planck_interface.so
;lensing
lensing_1 = ${PLANCKPATH}/lensing/smicadx12_Dec5_ftl_mv2_ndclpp_p_teb_consext8_CMBmarged.clik_lensing

[bbn]
file = likelihood/bbn/bbn_ombh2_pitrou20_cooke18/bbn_ombh2_pitrou20_cooke18.py

; This can be used to simulate a data vector from a pipeline
;[save_2pt]
;file = likelihood/2pt/save_2pt.py
;theta_min = 2.5
;theta_max = 250.0
;n_theta = 20
;real_space = T
;make_covariance = F
;shear_nz_name = nz_source
;position_nz_name = nz_lens

;filename = ${OUTPUT_DIR}/FitsFiles/sim_%(INI_RUN_NAME)s_${LENS_TAG}_${SOURCE_TAG}.fits
;overwrite = T
;auto_only = galaxy_xi
;cut_wtheta = 1,2 1,3 2,3 1,4 2,4 3,4 1,5 2,5 3,5 4,5
;spectrum_sections = shear_xi_plus shear_xi_minus 
;galaxy_shear_xi galaxy_xi
;output_extensions = xip xim 
;gammat wtheta
;two_thirds_midpoint = T
;copy_covariance=data_vectors/${DATA_VECTOR}

#This section saves the output

;[save_2pt]
;file = likelihood/2pt/save_2pt.py
;shear_nz_name=nz_source
;filename=/home/cp662/DES/powerPKZ/chains/FitFiles/sim_%(INI_RUN_NAME)s_${LENS_TAG}_${SOURCE_TAG}.fits
;clobber=T
;real_space=T
;copy_covariance = examples/lsst_forecast/lsst_simulation.fits
; This will make a Gaussian-only covariance
;make_covariance = F 
;copy_covariance=data_vectors/${DATA_VECTOR}
;cl_sections = shear_cl
;These values define the survey and the observations being made;
;First, some details of the survey itself:
;auto-only=
;fsky = 0.436
;#angelue scales
;theta_min = 2.5
;theta_max = 900.
;n_theta = 26
;ell_min = 20
;ell_max = 2627
;n_ell = 15
; sections to save
;cl_sections = shear_cl shear_cl 
;cl_to_xi_types = 22+ 22-
;spectrum_sections = shear_xi_plus shear_xi_minus
;spectrum_extensions = shear_cl
;output_extensions = xip xim
;overwrite=T
;verbose=T

[save_2pt]
file = likelihood/2pt/save_2pt.py
theta_min = 2.5
theta_max = 250.0
n_theta = 20
real_space = T
make_covariance = F
shear_nz_name = nz_source
position_nz_name = nz_lens

filename = ${OUTPUT_DIR}/sim_%(INI_RUN_NAME)s_${LENS_TAG}_${SOURCE_TAG}.fits
overwrite = T
auto_only = galaxy_xi
;cut_wtheta = 1,2 1,3 2,3 1,4 2,4 3,4 1,5 2,5 3,5 4,5
spectrum_sections = shear_xi_plus shear_xi_minus 
;galaxy_shear_xi galaxy_xi
output_extensions = xip xim 
;gammat wtheta
two_thirds_midpoint = T
copy_covariance=data_vectors/${DATA_VECTOR}

%include ${INCLUDEFILE}
